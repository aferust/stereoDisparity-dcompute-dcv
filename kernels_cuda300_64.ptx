//
// Generated by LLVM NVPTX Back-End
//

.version 3.2
.target sm_30
.address_size 64

	// .globl	_D7dispmap7__usad4FkkkZk
.visible .func  (.param .b32 func_retval0) _D7dispmap9packBytesFxPhZk
(
	.param .b64 _D7dispmap9packBytesFxPhZk_param_0
)
;
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm
()
;
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm
()
;
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm
()
;
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11SharedIndex__T1yZQdFNaNbNdNiZm
()
;
.weak .func _D8dcompute3std6memory__T19sharedStaticReserveHTG340kVAyaa5_6469666630Vmi340ZQCaFNbNiZS3ldcQDl__T7PointerVEQuQEd9AddrSpacei2TkZQBe
(
	.param .b64 _D8dcompute3std6memory__T19sharedStaticReserveHTG340kVAyaa5_6469666630Vmi340ZQCaFNbNiZS3ldcQDl__T7PointerVEQuQEd9AddrSpacei2TkZQBe_param_0
)
;
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.const .align 1 .b8 str[4] = {37, 100, 10, 0};
.visible .shared .align 4 .b8 diff0[1360];
.global .align 1 .b8 _$_str[4] = {51, 52, 48, 0};
.global .align 1 .b8 _$_str1[3] = {51, 52, 0};
.global .align 1 .b8 _$_str2[2] = {51, 0};
.global .align 1 .b8 _$_str3[2] = {52, 0};
.global .align 1 .b8 _$_str4[2] = {48, 0};
.global .align 1 .b8 _$_str5[4] = {105, 51, 50, 0};

.visible .func  (.param .b32 func_retval0) _D7dispmap7__usad4FkkkZk(
	.param .b32 _D7dispmap7__usad4FkkkZk_param_0,
	.param .b32 _D7dispmap7__usad4FkkkZk_param_1,
	.param .b32 _D7dispmap7__usad4FkkkZk_param_2
)
{
	.local .align 4 .b8 	__local_depot0[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<9>;

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r3, [_D7dispmap7__usad4FkkkZk_param_2];
	ld.param.u32 	%r2, [_D7dispmap7__usad4FkkkZk_param_1];
	ld.param.u32 	%r1, [_D7dispmap7__usad4FkkkZk_param_0];
	st.u32 	[%SP+0], %r1;
	st.u32 	[%SP+4], %r2;
	st.u32 	[%SP+8], %r3;
	ld.u32 	%r5, [%SP+0];
	ld.u32 	%r6, [%SP+4];
	ld.u32 	%r7, [%SP+8];
	// begin inline asm
	vabsdiff4.u32.u32.u32.add %r4, %r5, %r6, %r7;
	// end inline asm
	st.u32 	[%SP+12], %r4;
	ld.u32 	%r8, [%SP+12];
	st.param.b32 	[func_retval0+0], %r8;
	ret;

}
	// .globl	_D7dispmap5toIntFSQq4int4Zk
.visible .func  (.param .b32 func_retval0) _D7dispmap5toIntFSQq4int4Zk(
	.param .align 4 .b8 _D7dispmap5toIntFSQq4int4Zk_param_0[16]
)
{
	.local .align 8 .b8 	__local_depot1[24];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<4>;

	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r4, [_D7dispmap5toIntFSQq4int4Zk_param_0+12];
	ld.param.u32 	%r3, [_D7dispmap5toIntFSQq4int4Zk_param_0+8];
	ld.param.u32 	%r2, [_D7dispmap5toIntFSQq4int4Zk_param_0+4];
	ld.param.u32 	%r1, [_D7dispmap5toIntFSQq4int4Zk_param_0];
	add.u64 	%rd1, %SP, 0;
	or.b64  	%rd2, %rd1, 4;
	st.u32 	[%rd2], %r2;
	st.u32 	[%SP+12], %r4;
	st.u32 	[%SP+8], %r3;
	st.u32 	[%SP+0], %r1;
	mov.u32 	%r5, 0;
	st.u32 	[%SP+16], %r5;
	ld.u32 	%r6, [%SP+0];
	st.u8 	[%SP+20], %r6;
	ld.u32 	%r7, [%rd2];
	st.u8 	[%SP+21], %r7;
	ld.u32 	%r8, [%SP+8];
	st.u8 	[%SP+22], %r8;
	ld.u32 	%r9, [%SP+12];
	st.u8 	[%SP+23], %r9;
	add.u64 	%rd3, %SP, 20;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd3;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap9packBytesFxPhZk, 
	(
	param0
	);
	ld.param.b32 	%r10, [retval0+0];
	} // callseq 0
	st.u32 	[%SP+16], %r10;
	ld.u32 	%r12, [%SP+16];
	st.param.b32 	[func_retval0+0], %r12;
	ret;

}
	// .globl	_D7dispmap9packBytesFxPhZk
.visible .func  (.param .b32 func_retval0) _D7dispmap9packBytesFxPhZk(
	.param .b64 _D7dispmap9packBytesFxPhZk_param_0
)
{
	.local .align 8 .b8 	__local_depot2[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<3>;

	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_D7dispmap9packBytesFxPhZk_param_0];
	st.u64 	[%SP+0], %rd1;
	ld.u64 	%rd2, [%SP+0];
	ld.u8 	%r1, [%rd2];
	ld.u8 	%r2, [%rd2+1];
	shl.b32 	%r3, %r2, 8;
	or.b32  	%r4, %r1, %r3;
	ld.u8 	%r5, [%rd2+2];
	shl.b32 	%r6, %r5, 16;
	or.b32  	%r7, %r4, %r6;
	ld.u8 	%r8, [%rd2+3];
	shl.b32 	%r9, %r8, 24;
	or.b32  	%r10, %r7, %r9;
	st.u32 	[%SP+8], %r10;
	ld.u32 	%r11, [%SP+8];
	st.param.b32 	[func_retval0+0], %r11;
	ret;

}
	// .globl	_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv
.visible .entry _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv(
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_0,
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_1,
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_2,
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_3,
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_4,
	.param .u32 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_5,
	.param .u32 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_6
)
{
	.local .align 8 .b8 	__local_depot3[280];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .b32 	%r<144>;
	.reg .b64 	%rd<110>;

	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r2, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_6];
	ld.param.u32 	%r1, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_5];
	ld.param.u64 	%rd5, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_4];
	ld.param.u64 	%rd4, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_3];
	ld.param.u64 	%rd3, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_2];
	ld.param.u64 	%rd2, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_1];
	ld.param.u64 	%rd1, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_0];
	st.u64 	[%SP+16], %rd1;
	st.u64 	[%SP+24], %rd2;
	st.u64 	[%SP+32], %rd3;
	st.u64 	[%SP+40], %rd4;
	st.u64 	[%SP+48], %rd5;
	st.u32 	[%SP+56], %r1;
	st.u32 	[%SP+60], %r2;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd6, [retval0+0];
	} // callseq 1
	st.u32 	[%SP+64], %rd6;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd8, [retval0+0];
	} // callseq 2
	st.u32 	[%SP+68], %rd8;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd10, [retval0+0];
	} // callseq 3
	add.s64 	%rd12, %rd10, 1;
	st.u64 	[%SP+72], %rd12;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11SharedIndex__T1yZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd13, [retval0+0];
	} // callseq 4
	add.s64 	%rd15, %rd13, 1;
	st.u64 	[%SP+80], %rd15;
	mov.u32 	%r3, 0;
	st.u32 	[%SP+88], %r3;
	st.u32 	[%SP+92], %r3;
	st.u32 	[%SP+96], %r3;
	mov.u32 	%r4, 9999999;
	st.u32 	[%SP+100], %r4;
	st.u32 	[%SP+104], %r3;
	add.u64 	%rd16, %SP, 112;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd16;
	call.uni 
	_D8dcompute3std6memory__T19sharedStaticReserveHTG340kVAyaa5_6469666630Vmi340ZQCaFNbNiZS3ldcQDl__T7PointerVEQuQEd9AddrSpacei2TkZQBe, 
	(
	param0
	);
	} // callseq 5
	add.u64 	%rd17, %SP, 0;
	st.u64 	[%SP+120], %rd17;
	st.u64 	[%SP+128], %rd17;
	st.u32 	[%SP+136], %r3;
	mov.u32 	%r5, 3;
	st.u32 	[%SP+140], %r5;
	bra.uni 	LBB3_1;
LBB3_1:
	ld.u32 	%r6, [%SP+136];
	ld.u32 	%r7, [%SP+140];
	setp.ge.s32 	%p3, %r6, %r7;
	@%p3 bra 	LBB3_4;
	bra.uni 	LBB3_2;
LBB3_2:
	ld.u32 	%r109, [%SP+136];
	st.u32 	[%SP+144], %r109;
	ld.u32 	%r110, [%SP+144];
	add.s32 	%r111, %r110, -1;
	st.u32 	[%SP+148], %r111;
	ld.s32 	%rd95, [%SP+144];
	ld.u64 	%rd96, [%SP+120];
	shl.b64 	%rd97, %rd95, 2;
	add.s64 	%rd98, %rd96, %rd97;
	ld.u64 	%rd99, [%SP+16];
	ld.u32 	%r112, [%SP+64];
	add.s32 	%r113, %r112, -1;
	ld.u32 	%r114, [%SP+68];
	ld.u32 	%r115, [%SP+148];
	add.s32 	%r116, %r114, %r115;
	tex.2d.v4.u32.s32 	{%r117, %r118, %r119, %r120}, [%rd99, {%r113, %r116}];
	mov.u64 	%rd100, 0;
	st.u64 	[%SP+160], %rd100;
	st.u64 	[%SP+152], %rd100;
	st.u32 	[%SP+152], %r117;
	add.u64 	%rd101, %SP, 152;
	or.b64  	%rd102, %rd101, 4;
	st.u32 	[%rd102], %r118;
	st.u32 	[%SP+160], %r119;
	st.u32 	[%SP+164], %r120;
	ld.u32 	%r121, [%rd102];
	ld.u32 	%r122, [%SP+164];
	ld.u32 	%r123, [%SP+160];
	ld.u32 	%r124, [%SP+152];
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .align 4 .b8 param0[16];
	st.param.b32 	[param0+0], %r124;
	st.param.b32 	[param0+4], %r121;
	st.param.b32 	[param0+8], %r123;
	st.param.b32 	[param0+12], %r122;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap5toIntFSQq4int4Zk, 
	(
	param0
	);
	ld.param.b32 	%r125, [retval0+0];
	} // callseq 11
	st.u32 	[%rd98], %r125;
	ld.s32 	%rd103, [%SP+144];
	ld.u64 	%rd104, [%SP+128];
	shl.b64 	%rd105, %rd103, 2;
	add.s64 	%rd106, %rd104, %rd105;
	ld.u64 	%rd107, [%SP+16];
	ld.u32 	%r127, [%SP+64];
	add.s32 	%r128, %r127, 31;
	ld.u32 	%r129, [%SP+68];
	ld.u32 	%r130, [%SP+148];
	add.s32 	%r131, %r129, %r130;
	tex.2d.v4.u32.s32 	{%r132, %r133, %r134, %r135}, [%rd107, {%r128, %r131}];
	st.u64 	[%SP+176], %rd100;
	st.u64 	[%SP+168], %rd100;
	st.u32 	[%SP+168], %r132;
	add.u64 	%rd108, %SP, 168;
	or.b64  	%rd109, %rd108, 4;
	st.u32 	[%rd109], %r133;
	st.u32 	[%SP+176], %r134;
	st.u32 	[%SP+180], %r135;
	ld.u32 	%r136, [%rd109];
	ld.u32 	%r137, [%SP+180];
	ld.u32 	%r138, [%SP+176];
	ld.u32 	%r139, [%SP+168];
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .align 4 .b8 param0[16];
	st.param.b32 	[param0+0], %r139;
	st.param.b32 	[param0+4], %r136;
	st.param.b32 	[param0+8], %r138;
	st.param.b32 	[param0+12], %r137;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap5toIntFSQq4int4Zk, 
	(
	param0
	);
	ld.param.b32 	%r140, [retval0+0];
	} // callseq 12
	st.u32 	[%rd106], %r140;
	bra.uni 	LBB3_3;
LBB3_3:
	ld.u32 	%r142, [%SP+136];
	add.s32 	%r143, %r142, 1;
	st.u32 	[%SP+136], %r143;
	bra.uni 	LBB3_1;
LBB3_4:
	ld.u32 	%r8, [%SP+56];
	st.u32 	[%SP+184], %r8;
	bra.uni 	LBB3_5;
LBB3_5:
	ld.u32 	%r9, [%SP+184];
	ld.u32 	%r10, [%SP+60];
	setp.gt.s32 	%p4, %r9, %r10;
	@%p4 bra 	LBB3_32;
	bra.uni 	LBB3_6;
LBB3_6:
	mov.u32 	%r12, 0;
	st.u32 	[%SP+188], %r12;
	mov.u32 	%r13, 3;
	st.u32 	[%SP+192], %r13;
	bra.uni 	LBB3_7;
LBB3_7:
	ld.u32 	%r14, [%SP+188];
	ld.u32 	%r15, [%SP+192];
	setp.ge.s32 	%p7, %r14, %r15;
	@%p7 bra 	LBB3_10;
	bra.uni 	LBB3_8;
LBB3_8:
	ld.u32 	%r81, [%SP+188];
	st.u32 	[%SP+196], %r81;
	ld.u32 	%r82, [%SP+196];
	add.s32 	%r83, %r82, -1;
	st.u32 	[%SP+200], %r83;
	ld.s32 	%rd78, [%SP+196];
	ld.u64 	%rd79, [%SP+120];
	shl.b64 	%rd80, %rd78, 2;
	add.s64 	%rd81, %rd79, %rd80;
	ld.u32 	%r84, [%rd81];
	st.u32 	[%SP+88], %r84;
	ld.u64 	%rd82, [%SP+24];
	ld.u32 	%r85, [%SP+64];
	ld.u32 	%r86, [%SP+184];
	add.s32 	%r87, %r85, %r86;
	add.s32 	%r88, %r87, -1;
	ld.u32 	%r89, [%SP+68];
	ld.u32 	%r90, [%SP+200];
	add.s32 	%r91, %r89, %r90;
	tex.2d.v4.u32.s32 	{%r92, %r93, %r94, %r95}, [%rd82, {%r88, %r91}];
	mov.u64 	%rd83, 0;
	st.u64 	[%SP+216], %rd83;
	st.u64 	[%SP+208], %rd83;
	st.u32 	[%SP+208], %r92;
	add.u64 	%rd84, %SP, 208;
	or.b64  	%rd85, %rd84, 4;
	st.u32 	[%rd85], %r93;
	st.u32 	[%SP+216], %r94;
	st.u32 	[%SP+220], %r95;
	ld.u32 	%r96, [%rd85];
	ld.u32 	%r97, [%SP+220];
	ld.u32 	%r98, [%SP+216];
	ld.u32 	%r99, [%SP+208];
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .align 4 .b8 param0[16];
	st.param.b32 	[param0+0], %r99;
	st.param.b32 	[param0+4], %r96;
	st.param.b32 	[param0+8], %r98;
	st.param.b32 	[param0+12], %r97;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap5toIntFSQq4int4Zk, 
	(
	param0
	);
	ld.param.b32 	%r100, [retval0+0];
	} // callseq 9
	st.u32 	[%SP+92], %r100;
	ld.u64 	%rd86, [%SP+80];
	ld.s32 	%rd87, [%SP+200];
	add.s64 	%rd88, %rd86, %rd87;
	mul.lo.s64 	%rd89, %rd88, 34;
	ld.u64 	%rd90, [%SP+72];
	add.s64 	%rd91, %rd90, %rd89;
	shl.b64 	%rd92, %rd91, 2;
	ld.u64 	%rd93, [%SP+112];
	add.s64 	%rd94, %rd92, %rd93;
	ld.u32 	%r102, [%SP+88];
	ld.u32 	%r103, [%SP+92];
	mov.u32 	%r104, 0;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r102;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r103;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r104;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap7__usad4FkkkZk, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r105, [retval0+0];
	} // callseq 10
	st.shared.u32 	[%rd94+-4], %r105;
	bra.uni 	LBB3_9;
LBB3_9:
	ld.u32 	%r107, [%SP+188];
	add.s32 	%r108, %r107, 1;
	st.u32 	[%SP+188], %r108;
	bra.uni 	LBB3_7;
LBB3_10:
	mov.u32 	%r16, 0;
	st.u32 	[%SP+224], %r16;
	mov.u32 	%r17, 3;
	st.u32 	[%SP+228], %r17;
	bra.uni 	LBB3_11;
LBB3_11:
	ld.u32 	%r18, [%SP+224];
	ld.u32 	%r19, [%SP+228];
	setp.ge.s32 	%p8, %r18, %r19;
	@%p8 bra 	LBB3_16;
	bra.uni 	LBB3_12;
LBB3_12:
	ld.u32 	%r53, [%SP+224];
	st.u32 	[%SP+232], %r53;
	ld.u32 	%r54, [%SP+232];
	add.s32 	%r55, %r54, -1;
	st.u32 	[%SP+236], %r55;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd59, [retval0+0];
	} // callseq 6
	setp.gt.u64 	%p13, %rd59, 1;
	@%p13 bra 	LBB3_14;
	bra.uni 	LBB3_13;
LBB3_13:
	ld.s32 	%rd61, [%SP+232];
	ld.u64 	%rd62, [%SP+128];
	shl.b64 	%rd63, %rd61, 2;
	add.s64 	%rd64, %rd62, %rd63;
	ld.u32 	%r56, [%rd64];
	st.u32 	[%SP+88], %r56;
	ld.u64 	%rd65, [%SP+24];
	ld.u32 	%r57, [%SP+64];
	ld.u32 	%r58, [%SP+184];
	add.s32 	%r59, %r57, %r58;
	add.s32 	%r60, %r59, 31;
	ld.u32 	%r61, [%SP+68];
	ld.u32 	%r62, [%SP+236];
	add.s32 	%r63, %r61, %r62;
	tex.2d.v4.u32.s32 	{%r64, %r65, %r66, %r67}, [%rd65, {%r60, %r63}];
	mov.u64 	%rd66, 0;
	st.u64 	[%SP+248], %rd66;
	st.u64 	[%SP+240], %rd66;
	st.u32 	[%SP+240], %r64;
	add.u64 	%rd67, %SP, 240;
	or.b64  	%rd68, %rd67, 4;
	st.u32 	[%rd68], %r65;
	st.u32 	[%SP+248], %r66;
	st.u32 	[%SP+252], %r67;
	ld.u32 	%r68, [%rd68];
	ld.u32 	%r69, [%SP+252];
	ld.u32 	%r70, [%SP+248];
	ld.u32 	%r71, [%SP+240];
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .align 4 .b8 param0[16];
	st.param.b32 	[param0+0], %r71;
	st.param.b32 	[param0+4], %r68;
	st.param.b32 	[param0+8], %r70;
	st.param.b32 	[param0+12], %r69;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap5toIntFSQq4int4Zk, 
	(
	param0
	);
	ld.param.b32 	%r72, [retval0+0];
	} // callseq 7
	st.u32 	[%SP+92], %r72;
	ld.u64 	%rd69, [%SP+80];
	ld.s32 	%rd70, [%SP+236];
	add.s64 	%rd71, %rd69, %rd70;
	mul.lo.s64 	%rd72, %rd71, 34;
	ld.u64 	%rd73, [%SP+72];
	add.s64 	%rd74, %rd73, %rd72;
	shl.b64 	%rd75, %rd74, 2;
	ld.u64 	%rd76, [%SP+112];
	add.s64 	%rd77, %rd75, %rd76;
	ld.u32 	%r74, [%SP+88];
	ld.u32 	%r75, [%SP+92];
	mov.u32 	%r76, 0;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r74;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r75;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r76;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap7__usad4FkkkZk, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r77, [retval0+0];
	} // callseq 8
	st.shared.u32 	[%rd77+124], %r77;
	bra.uni 	LBB3_14;
LBB3_14:
	bra.uni 	LBB3_15;
LBB3_15:
	ld.u32 	%r79, [%SP+224];
	add.s32 	%r80, %r79, 1;
	st.u32 	[%SP+224], %r80;
	bra.uni 	LBB3_11;
LBB3_16:
	bar.sync 	0;
	mov.u32 	%r20, 0;
	st.u32 	[%SP+256], %r20;
	mov.u32 	%r21, 3;
	st.u32 	[%SP+260], %r21;
	bra.uni 	LBB3_17;
LBB3_17:
	ld.u32 	%r22, [%SP+256];
	ld.u32 	%r23, [%SP+260];
	setp.ge.s32 	%p9, %r22, %r23;
	@%p9 bra 	LBB3_24;
	bra.uni 	LBB3_18;
LBB3_18:
	ld.u32 	%r39, [%SP+256];
	st.u32 	[%SP+264], %r39;
	ld.u32 	%r40, [%SP+264];
	add.s32 	%r41, %r40, -1;
	st.u32 	[%SP+268], %r41;
	mov.u32 	%r42, 0;
	st.u32 	[%SP+96], %r42;
	mov.u32 	%r43, -1;
	st.u32 	[%SP+272], %r43;
	bra.uni 	LBB3_19;
LBB3_19:
	ld.u32 	%r44, [%SP+272];
	setp.gt.s32 	%p12, %r44, 1;
	@%p12 bra 	LBB3_22;
	bra.uni 	LBB3_20;
LBB3_20:
	ld.u64 	%rd48, [%SP+80];
	ld.s32 	%rd49, [%SP+268];
	add.s64 	%rd50, %rd48, %rd49;
	mul.lo.s64 	%rd51, %rd50, 34;
	ld.u64 	%rd52, [%SP+72];
	ld.s32 	%rd53, [%SP+272];
	add.s64 	%rd54, %rd52, %rd53;
	add.s64 	%rd55, %rd51, %rd54;
	ld.u64 	%rd56, [%SP+112];
	shl.b64 	%rd57, %rd55, 2;
	add.s64 	%rd58, %rd56, %rd57;
	ld.shared.u32 	%r48, [%rd58];
	ld.u32 	%r49, [%SP+96];
	add.s32 	%r50, %r49, %r48;
	st.u32 	[%SP+96], %r50;
	bra.uni 	LBB3_21;
LBB3_21:
	ld.u32 	%r51, [%SP+272];
	add.s32 	%r52, %r51, 1;
	st.u32 	[%SP+272], %r52;
	bra.uni 	LBB3_19;
LBB3_22:
	bar.sync 	0;
	ld.u64 	%rd39, [%SP+80];
	ld.s32 	%rd40, [%SP+268];
	add.s64 	%rd41, %rd39, %rd40;
	mul.lo.s64 	%rd42, %rd41, 34;
	ld.u64 	%rd43, [%SP+72];
	add.s64 	%rd44, %rd42, %rd43;
	ld.u64 	%rd45, [%SP+112];
	shl.b64 	%rd46, %rd44, 2;
	add.s64 	%rd47, %rd45, %rd46;
	ld.u32 	%r45, [%SP+96];
	st.shared.u32 	[%rd47], %r45;
	bar.sync 	0;
	bra.uni 	LBB3_23;
LBB3_23:
	ld.u32 	%r46, [%SP+256];
	add.s32 	%r47, %r46, 1;
	st.u32 	[%SP+256], %r47;
	bra.uni 	LBB3_17;
LBB3_24:
	mov.u32 	%r24, 0;
	st.u32 	[%SP+96], %r24;
	mov.u32 	%r25, -1;
	st.u32 	[%SP+276], %r25;
	bra.uni 	LBB3_25;
LBB3_25:
	ld.u32 	%r26, [%SP+276];
	setp.gt.s32 	%p10, %r26, 1;
	@%p10 bra 	LBB3_28;
	bra.uni 	LBB3_26;
LBB3_26:
	ld.u64 	%rd30, [%SP+80];
	ld.s32 	%rd31, [%SP+276];
	add.s64 	%rd32, %rd30, %rd31;
	mul.lo.s64 	%rd33, %rd32, 34;
	ld.u64 	%rd34, [%SP+72];
	add.s64 	%rd35, %rd33, %rd34;
	ld.u64 	%rd36, [%SP+112];
	shl.b64 	%rd37, %rd35, 2;
	add.s64 	%rd38, %rd36, %rd37;
	ld.shared.u32 	%r34, [%rd38];
	ld.u32 	%r35, [%SP+96];
	add.s32 	%r36, %r35, %r34;
	st.u32 	[%SP+96], %r36;
	bra.uni 	LBB3_27;
LBB3_27:
	ld.u32 	%r37, [%SP+276];
	add.s32 	%r38, %r37, 1;
	st.u32 	[%SP+276], %r38;
	bra.uni 	LBB3_25;
LBB3_28:
	ld.u32 	%r27, [%SP+96];
	ld.u32 	%r28, [%SP+100];
	setp.ge.u32 	%p11, %r27, %r28;
	@%p11 bra 	LBB3_30;
	bra.uni 	LBB3_29;
LBB3_29:
	ld.u32 	%r29, [%SP+96];
	st.u32 	[%SP+100], %r29;
	ld.u32 	%r30, [%SP+184];
	add.s32 	%r31, %r30, 8;
	st.u32 	[%SP+104], %r31;
	bra.uni 	LBB3_30;
LBB3_30:
	bar.sync 	0;
	bra.uni 	LBB3_31;
LBB3_31:
	ld.u32 	%r32, [%SP+184];
	add.s32 	%r33, %r32, 1;
	st.u32 	[%SP+184], %r33;
	bra.uni 	LBB3_5;
LBB3_32:
	ld.s32 	%rd18, [%SP+68];
	ld.u64 	%rd19, [%SP+48];
	setp.ge.u64 	%p6, %rd18, %rd19;
	mov.pred 	%p5, 0;
	mov.pred 	%p14, %p5;
	@%p6 bra 	LBB3_34;
	bra.uni 	LBB3_33;
LBB3_33:
	ld.s32 	%rd20, [%SP+64];
	ld.u64 	%rd21, [%SP+40];
	setp.lt.u64 	%p1, %rd20, %rd21;
	mov.pred 	%p14, %p1;
	bra.uni 	LBB3_34;
LBB3_34:
	mov.pred 	%p2, %p14;
	@!%p2 bra 	LBB3_36;
	bra.uni 	LBB3_35;
LBB3_35:
	ld.s32 	%rd22, [%SP+68];
	ld.u64 	%rd23, [%SP+40];
	mul.lo.s64 	%rd24, %rd22, %rd23;
	ld.s32 	%rd25, [%SP+64];
	add.s64 	%rd26, %rd24, %rd25;
	ld.u64 	%rd27, [%SP+32];
	shl.b64 	%rd28, %rd26, 2;
	add.s64 	%rd29, %rd27, %rd28;
	ld.u32 	%r11, [%SP+104];
	st.global.u32 	[%rd29], %r11;
	bra.uni 	LBB3_36;
LBB3_36:
	ret;

}
	// .weak	_D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm()
{
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<2>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r3, %r1, %r2;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	cvt.u64.u32 	%rd1, %r5;
	st.param.b64 	[func_retval0+0], %rd1;
	ret;

}
	// .weak	_D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm()
{
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<2>;

	mov.u32 	%r1, %ctaid.y;
	mov.u32 	%r2, %ntid.y;
	mul.lo.s32 	%r3, %r1, %r2;
	mov.u32 	%r4, %tid.y;
	add.s32 	%r5, %r3, %r4;
	cvt.u64.u32 	%rd1, %r5;
	st.param.b64 	[func_retval0+0], %rd1;
	ret;

}
	// .weak	_D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm()
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<2>;

	mov.u32 	%r1, %tid.x;
	cvt.u64.u32 	%rd1, %r1;
	st.param.b64 	[func_retval0+0], %rd1;
	ret;

}
	// .weak	_D8dcompute3std5index11SharedIndex__T1yZQdFNaNbNdNiZm
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11SharedIndex__T1yZQdFNaNbNdNiZm()
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<2>;

	mov.u32 	%r1, %tid.y;
	cvt.u64.u32 	%rd1, %r1;
	st.param.b64 	[func_retval0+0], %rd1;
	ret;

}
	// .weak	_D8dcompute3std6memory__T19sharedStaticReserveHTG340kVAyaa5_6469666630Vmi340ZQCaFNbNiZS3ldcQDl__T7PointerVEQuQEd9AddrSpacei2TkZQBe
.weak .func _D8dcompute3std6memory__T19sharedStaticReserveHTG340kVAyaa5_6469666630Vmi340ZQCaFNbNiZS3ldcQDl__T7PointerVEQuQEd9AddrSpacei2TkZQBe(
	.param .b64 _D8dcompute3std6memory__T19sharedStaticReserveHTG340kVAyaa5_6469666630Vmi340ZQCaFNbNiZS3ldcQDl__T7PointerVEQuQEd9AddrSpacei2TkZQBe_param_0
)
{
	.local .align 8 .b8 	__local_depot8[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b16 	%rs<9>;
	.reg .b64 	%rd<5>;

	mov.u64 	%SPL, __local_depot8;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_D8dcompute3std6memory__T19sharedStaticReserveHTG340kVAyaa5_6469666630Vmi340ZQCaFNbNiZS3ldcQDl__T7PointerVEQuQEd9AddrSpacei2TkZQBe_param_0];
	mov.u64 	%rd2, diff0;
	st.u64 	[%SP+0], %rd2;
	add.u64 	%rd3, %SP, 0;
	st.u64 	[%SP+8], %rd3;
	ld.u64 	%rd4, [%SP+8];
	ld.u8 	%rs1, [%rd4+7];
	st.u8 	[%rd1+7], %rs1;
	ld.u8 	%rs2, [%rd4+6];
	st.u8 	[%rd1+6], %rs2;
	ld.u8 	%rs3, [%rd4+5];
	st.u8 	[%rd1+5], %rs3;
	ld.u8 	%rs4, [%rd4+4];
	st.u8 	[%rd1+4], %rs4;
	ld.u8 	%rs5, [%rd4+3];
	st.u8 	[%rd1+3], %rs5;
	ld.u8 	%rs6, [%rd4+2];
	st.u8 	[%rd1+2], %rs6;
	ld.u8 	%rs7, [%rd4+1];
	st.u8 	[%rd1+1], %rs7;
	ld.u8 	%rs8, [%rd4];
	st.u8 	[%rd1], %rs8;
	ret;

}
	// .globl	_D7dispmap8printIntFkZv
.visible .func _D7dispmap8printIntFkZv(
	.param .b32 _D7dispmap8printIntFkZv_param_0
)
{
	.local .align 8 .b8 	__local_depot9[56];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<5>;

	mov.u64 	%SPL, __local_depot9;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r1, [_D7dispmap8printIntFkZv_param_0];
	st.u32 	[%SP+48], %r1;
	ld.u32 	%r2, [%SP+48];
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r2;
	mov.u64 	%rd3, str;
	cvta.const.u64 	%rd4, %rd3;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 13
	ret;

}
	// .globl	_D7dispmap11reserveInt4FZPSQz4int4
.visible .func  (.param .b64 func_retval0) _D7dispmap11reserveInt4FZPSQz4int4()
{
	.local .align 8 .b8 	__local_depot10[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b64 	%rd<4>;

	mov.u64 	%SPL, __local_depot10;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd1, %SP, 0;
	st.u64 	[%SP+48], %rd1;
	ld.u64 	%rd2, [%SP+48];
	st.u64 	[%SP+56], %rd2;
	ld.u64 	%rd3, [%SP+56];
	st.param.b64 	[func_retval0+0], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T4ItoaVki340ZQmFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T4ItoaVki340ZQmFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 3;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T4ItoaVki34ZQlFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T4ItoaVki34ZQlFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 2;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str1;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T4ItoaVki3ZQkFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T4ItoaVki3ZQkFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 1;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str2;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T5DigitVmi3ZQlFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T5DigitVmi3ZQlFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 1;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str2;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T5DigitVmi4ZQlFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T5DigitVmi4ZQlFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 1;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str3;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T5DigitVmi0ZQlFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T5DigitVmi0ZQlFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 1;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str4;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T8llvmTypeTkZQmFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T8llvmTypeTkZQmFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 3;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str5;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
