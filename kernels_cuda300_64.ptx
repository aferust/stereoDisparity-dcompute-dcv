//
// Generated by LLVM NVPTX Back-End
//

.version 3.2
.target sm_30
.address_size 64

	// .globl	_D7dispmap7__usad4FkkkZk
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm
()
;
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm
()
;
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm
()
;
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11SharedIndex__T1yZQdFNaNbNdNiZm
()
;
.weak .func _D8dcompute3std6memory__T19sharedStaticReserveHTG1152kVAyaa5_6469666630Vmi1152ZQCcFNbNiZS3ldcQDn__T7PointerVEQuQEf9AddrSpacei2TkZQBe
(
	.param .b64 _D8dcompute3std6memory__T19sharedStaticReserveHTG1152kVAyaa5_6469666630Vmi1152ZQCcFNbNiZS3ldcQDn__T7PointerVEQuQEf9AddrSpacei2TkZQBe_param_0
)
;
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.weak .func  (.param .b32 func_retval0) _D9bilateral__T3absTfZQhFNaNbNiNefZf
(
	.param .b32 _D9bilateral__T3absTfZQhFNaNbNiNefZf_param_0
)
;
.weak .func _D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi
(
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_0,
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_1,
	.param .align 4 .b8 _D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_2[16]
)
;
.weak .func _D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv
(
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_0,
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_1,
	.param .b32 _D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_2
)
;
.weak .func _D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv
(
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_0,
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_1,
	.param .b32 _D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_2
)
;
.const .align 1 .b8 str[4] = {37, 100, 10, 0};
.const .align 1 .b8 str1[4] = {37, 102, 10, 0};
.visible .shared .align 4 .b8 diff0[4608];
.global .align 1 .b8 _$_str[5] = {49, 49, 53, 50, 0};
.global .align 1 .b8 _$_str2[4] = {49, 49, 53, 0};
.global .align 1 .b8 _$_str3[3] = {49, 49, 0};
.global .align 1 .b8 _$_str4[2] = {49, 0};
.global .align 1 .b8 _$_str5[2] = {53, 0};
.global .align 1 .b8 _$_str6[2] = {50, 0};
.global .align 1 .b8 _$_str7[4] = {105, 51, 50, 0};
.extern .global .align 4 .b8 _D9bilateral6float46__initZ[16];

.visible .func  (.param .b32 func_retval0) _D7dispmap7__usad4FkkkZk(
	.param .b32 _D7dispmap7__usad4FkkkZk_param_0,
	.param .b32 _D7dispmap7__usad4FkkkZk_param_1,
	.param .b32 _D7dispmap7__usad4FkkkZk_param_2
)
{
	.local .align 4 .b8 	__local_depot0[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<9>;

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r3, [_D7dispmap7__usad4FkkkZk_param_2];
	ld.param.u32 	%r2, [_D7dispmap7__usad4FkkkZk_param_1];
	ld.param.u32 	%r1, [_D7dispmap7__usad4FkkkZk_param_0];
	st.u32 	[%SP+0], %r1;
	st.u32 	[%SP+4], %r2;
	st.u32 	[%SP+8], %r3;
	ld.u32 	%r5, [%SP+0];
	ld.u32 	%r6, [%SP+4];
	ld.u32 	%r7, [%SP+8];
	// begin inline asm
	vabsdiff4.u32.u32.u32.add %r4, %r5, %r6, %r7;
	// end inline asm
	st.u32 	[%SP+12], %r4;
	ld.u32 	%r8, [%SP+12];
	st.param.b32 	[func_retval0+0], %r8;
	ret;

}
	// .globl	_D7dispmap5tex2DFmiiZk
.visible .func  (.param .b32 func_retval0) _D7dispmap5tex2DFmiiZk(
	.param .b64 _D7dispmap5tex2DFmiiZk_param_0,
	.param .b32 _D7dispmap5tex2DFmiiZk_param_1,
	.param .b32 _D7dispmap5tex2DFmiiZk_param_2
)
{
	.local .align 8 .b8 	__local_depot1[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<6>;

	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r2, [_D7dispmap5tex2DFmiiZk_param_2];
	ld.param.u32 	%r1, [_D7dispmap5tex2DFmiiZk_param_1];
	ld.param.u64 	%rd1, [_D7dispmap5tex2DFmiiZk_param_0];
	st.u64 	[%SP+0], %rd1;
	st.u32 	[%SP+8], %r1;
	st.u32 	[%SP+12], %r2;
	ld.u64 	%rd2, [%SP+0];
	ld.u32 	%r3, [%SP+8];
	ld.u32 	%r4, [%SP+12];
	tex.2d.v4.u32.s32 	{%r5, %r6, %r7, %r8}, [%rd2, {%r3, %r4}];
	mov.u64 	%rd3, 0;
	st.u64 	[%SP+24], %rd3;
	st.u64 	[%SP+16], %rd3;
	st.u32 	[%SP+16], %r5;
	add.u64 	%rd4, %SP, 16;
	or.b64  	%rd5, %rd4, 4;
	st.u32 	[%rd5], %r6;
	st.u32 	[%SP+24], %r7;
	st.u32 	[%SP+28], %r8;
	ld.u32 	%r9, [%SP+16];
	st.param.b32 	[func_retval0+0], %r9;
	ret;

}
	// .globl	_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv
.visible .entry _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv(
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_0,
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_1,
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_2,
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_3,
	.param .u64 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_4,
	.param .u32 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_5,
	.param .u32 _D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_6
)
{
	.local .align 8 .b8 	__local_depot2[232];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .b32 	%r<116>;
	.reg .b64 	%rd<101>;

	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r2, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_6];
	ld.param.u32 	%r1, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_5];
	ld.param.u64 	%rd5, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_4];
	ld.param.u64 	%rd4, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_3];
	ld.param.u64 	%rd3, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_2];
	ld.param.u64 	%rd2, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_1];
	ld.param.u64 	%rd1, [_D7dispmap21stereoDisparityKernelFmmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmiiZv_param_0];
	st.u64 	[%SP+0], %rd1;
	st.u64 	[%SP+8], %rd2;
	st.u64 	[%SP+16], %rd3;
	st.u64 	[%SP+24], %rd4;
	st.u64 	[%SP+32], %rd5;
	st.u32 	[%SP+40], %r1;
	st.u32 	[%SP+44], %r2;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd6, [retval0+0];
	} // callseq 0
	st.u32 	[%SP+48], %rd6;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd8, [retval0+0];
	} // callseq 1
	st.u32 	[%SP+52], %rd8;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd10, [retval0+0];
	} // callseq 2
	add.s64 	%rd12, %rd10, 8;
	st.u64 	[%SP+56], %rd12;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11SharedIndex__T1yZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd13, [retval0+0];
	} // callseq 3
	add.s64 	%rd15, %rd13, 8;
	st.u64 	[%SP+64], %rd15;
	mov.u32 	%r3, 0;
	st.u32 	[%SP+72], %r3;
	st.u32 	[%SP+76], %r3;
	st.u32 	[%SP+80], %r3;
	mov.u32 	%r4, 9999999;
	st.u32 	[%SP+84], %r4;
	st.u32 	[%SP+88], %r3;
	add.u64 	%rd16, %SP, 96;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd16;
	call.uni 
	_D8dcompute3std6memory__T19sharedStaticReserveHTG1152kVAyaa5_6469666630Vmi1152ZQCcFNbNiZS3ldcQDn__T7PointerVEQuQEf9AddrSpacei2TkZQBe, 
	(
	param0
	);
	} // callseq 4
	st.u32 	[%SP+112], %r3;
	mov.u64 	%rd17, 0;
	st.u64 	[%SP+104], %rd17;
	st.u32 	[%SP+128], %r3;
	st.u64 	[%SP+120], %rd17;
	add.u64 	%rd18, %SP, 104;
	st.u64 	[%SP+136], %rd18;
	add.u64 	%rd19, %SP, 120;
	st.u64 	[%SP+144], %rd19;
	st.u32 	[%SP+152], %r3;
	mov.u32 	%r5, 3;
	st.u32 	[%SP+156], %r5;
	bra.uni 	LBB2_1;
LBB2_1:
	ld.u32 	%r6, [%SP+152];
	ld.u32 	%r7, [%SP+156];
	setp.ge.s32 	%p3, %r6, %r7;
	@%p3 bra 	LBB2_4;
	bra.uni 	LBB2_2;
LBB2_2:
	ld.u32 	%r96, [%SP+152];
	st.u32 	[%SP+160], %r96;
	ld.u32 	%r97, [%SP+160];
	shl.b32 	%r98, %r97, 3;
	add.s32 	%r99, %r98, -8;
	st.u32 	[%SP+164], %r99;
	ld.s32 	%rd91, [%SP+160];
	ld.u64 	%rd92, [%SP+136];
	shl.b64 	%rd93, %rd91, 2;
	add.s64 	%rd94, %rd92, %rd93;
	ld.u64 	%rd95, [%SP+0];
	ld.u32 	%r100, [%SP+48];
	add.s32 	%r101, %r100, -8;
	ld.u32 	%r102, [%SP+52];
	ld.u32 	%r103, [%SP+164];
	add.s32 	%r104, %r102, %r103;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd95;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r101;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r104;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap5tex2DFmiiZk, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r105, [retval0+0];
	} // callseq 10
	st.u32 	[%rd94], %r105;
	ld.s32 	%rd96, [%SP+160];
	ld.u64 	%rd97, [%SP+144];
	shl.b64 	%rd98, %rd96, 2;
	add.s64 	%rd99, %rd97, %rd98;
	ld.u64 	%rd100, [%SP+0];
	ld.u32 	%r107, [%SP+48];
	add.s32 	%r108, %r107, 24;
	ld.u32 	%r109, [%SP+52];
	ld.u32 	%r110, [%SP+164];
	add.s32 	%r111, %r109, %r110;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd100;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r108;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r111;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap5tex2DFmiiZk, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r112, [retval0+0];
	} // callseq 11
	st.u32 	[%rd99], %r112;
	bra.uni 	LBB2_3;
LBB2_3:
	ld.u32 	%r114, [%SP+152];
	add.s32 	%r115, %r114, 1;
	st.u32 	[%SP+152], %r115;
	bra.uni 	LBB2_1;
LBB2_4:
	ld.u32 	%r8, [%SP+40];
	st.u32 	[%SP+168], %r8;
	bra.uni 	LBB2_5;
LBB2_5:
	ld.u32 	%r9, [%SP+168];
	ld.u32 	%r10, [%SP+44];
	setp.gt.s32 	%p4, %r9, %r10;
	@%p4 bra 	LBB2_32;
	bra.uni 	LBB2_6;
LBB2_6:
	mov.u32 	%r12, 0;
	st.u32 	[%SP+172], %r12;
	mov.u32 	%r13, 3;
	st.u32 	[%SP+176], %r13;
	bra.uni 	LBB2_7;
LBB2_7:
	ld.u32 	%r14, [%SP+172];
	ld.u32 	%r15, [%SP+176];
	setp.ge.s32 	%p7, %r14, %r15;
	@%p7 bra 	LBB2_10;
	bra.uni 	LBB2_8;
LBB2_8:
	ld.u32 	%r75, [%SP+172];
	st.u32 	[%SP+180], %r75;
	ld.u32 	%r76, [%SP+180];
	shl.b32 	%r77, %r76, 3;
	add.s32 	%r78, %r77, -8;
	st.u32 	[%SP+184], %r78;
	ld.s32 	%rd77, [%SP+180];
	ld.u64 	%rd78, [%SP+136];
	shl.b64 	%rd79, %rd77, 2;
	add.s64 	%rd80, %rd78, %rd79;
	ld.u32 	%r79, [%rd80];
	st.u32 	[%SP+72], %r79;
	ld.u64 	%rd81, [%SP+8];
	ld.u32 	%r80, [%SP+48];
	ld.u32 	%r81, [%SP+168];
	add.s32 	%r82, %r80, %r81;
	add.s32 	%r83, %r82, -8;
	ld.u32 	%r84, [%SP+52];
	ld.u32 	%r85, [%SP+184];
	add.s32 	%r86, %r84, %r85;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd81;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r83;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r86;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap5tex2DFmiiZk, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r87, [retval0+0];
	} // callseq 8
	st.u32 	[%SP+76], %r87;
	ld.u64 	%rd82, [%SP+64];
	ld.s32 	%rd83, [%SP+184];
	add.s64 	%rd84, %rd82, %rd83;
	mul.lo.s64 	%rd85, %rd84, 48;
	ld.u64 	%rd86, [%SP+56];
	add.s64 	%rd87, %rd86, %rd85;
	shl.b64 	%rd88, %rd87, 2;
	ld.u64 	%rd89, [%SP+96];
	add.s64 	%rd90, %rd88, %rd89;
	ld.u32 	%r89, [%SP+72];
	ld.u32 	%r90, [%SP+76];
	mov.u32 	%r91, 0;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r89;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r90;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r91;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap7__usad4FkkkZk, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r92, [retval0+0];
	} // callseq 9
	st.shared.u32 	[%rd90+-32], %r92;
	bra.uni 	LBB2_9;
LBB2_9:
	ld.u32 	%r94, [%SP+172];
	add.s32 	%r95, %r94, 1;
	st.u32 	[%SP+172], %r95;
	bra.uni 	LBB2_7;
LBB2_10:
	mov.u32 	%r16, 0;
	st.u32 	[%SP+188], %r16;
	mov.u32 	%r17, 3;
	st.u32 	[%SP+192], %r17;
	bra.uni 	LBB2_11;
LBB2_11:
	ld.u32 	%r18, [%SP+188];
	ld.u32 	%r19, [%SP+192];
	setp.ge.s32 	%p8, %r18, %r19;
	@%p8 bra 	LBB2_16;
	bra.uni 	LBB2_12;
LBB2_12:
	ld.u32 	%r54, [%SP+188];
	st.u32 	[%SP+196], %r54;
	ld.u32 	%r55, [%SP+196];
	shl.b32 	%r56, %r55, 3;
	add.s32 	%r57, %r56, -8;
	st.u32 	[%SP+200], %r57;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd61, [retval0+0];
	} // callseq 5
	setp.gt.u64 	%p13, %rd61, 15;
	@%p13 bra 	LBB2_14;
	bra.uni 	LBB2_13;
LBB2_13:
	ld.s32 	%rd63, [%SP+196];
	ld.u64 	%rd64, [%SP+144];
	shl.b64 	%rd65, %rd63, 2;
	add.s64 	%rd66, %rd64, %rd65;
	ld.u32 	%r58, [%rd66];
	st.u32 	[%SP+72], %r58;
	ld.u64 	%rd67, [%SP+8];
	ld.u32 	%r59, [%SP+48];
	ld.u32 	%r60, [%SP+168];
	add.s32 	%r61, %r59, %r60;
	add.s32 	%r62, %r61, 24;
	ld.u32 	%r63, [%SP+52];
	ld.u32 	%r64, [%SP+200];
	add.s32 	%r65, %r63, %r64;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd67;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r62;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r65;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap5tex2DFmiiZk, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r66, [retval0+0];
	} // callseq 6
	st.u32 	[%SP+76], %r66;
	ld.u64 	%rd68, [%SP+64];
	ld.s32 	%rd69, [%SP+200];
	add.s64 	%rd70, %rd68, %rd69;
	mul.lo.s64 	%rd71, %rd70, 48;
	ld.u64 	%rd72, [%SP+56];
	add.s64 	%rd73, %rd72, %rd71;
	shl.b64 	%rd74, %rd73, 2;
	ld.u64 	%rd75, [%SP+96];
	add.s64 	%rd76, %rd74, %rd75;
	ld.u32 	%r68, [%SP+72];
	ld.u32 	%r69, [%SP+76];
	mov.u32 	%r70, 0;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r68;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r69;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r70;
	.param .b32 retval0;
	call.uni (retval0), 
	_D7dispmap7__usad4FkkkZk, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32 	%r71, [retval0+0];
	} // callseq 7
	st.shared.u32 	[%rd76+96], %r71;
	bra.uni 	LBB2_14;
LBB2_14:
	bra.uni 	LBB2_15;
LBB2_15:
	ld.u32 	%r73, [%SP+188];
	add.s32 	%r74, %r73, 1;
	st.u32 	[%SP+188], %r74;
	bra.uni 	LBB2_11;
LBB2_16:
	bar.sync 	0;
	mov.u32 	%r20, 0;
	st.u32 	[%SP+204], %r20;
	mov.u32 	%r21, 3;
	st.u32 	[%SP+208], %r21;
	bra.uni 	LBB2_17;
LBB2_17:
	ld.u32 	%r22, [%SP+204];
	ld.u32 	%r23, [%SP+208];
	setp.ge.s32 	%p9, %r22, %r23;
	@%p9 bra 	LBB2_24;
	bra.uni 	LBB2_18;
LBB2_18:
	ld.u32 	%r39, [%SP+204];
	st.u32 	[%SP+212], %r39;
	ld.u32 	%r40, [%SP+212];
	shl.b32 	%r41, %r40, 3;
	add.s32 	%r42, %r41, -8;
	st.u32 	[%SP+216], %r42;
	mov.u32 	%r43, 0;
	st.u32 	[%SP+80], %r43;
	mov.u32 	%r44, -8;
	st.u32 	[%SP+220], %r44;
	bra.uni 	LBB2_19;
LBB2_19:
	ld.u32 	%r45, [%SP+220];
	setp.gt.s32 	%p12, %r45, 8;
	@%p12 bra 	LBB2_22;
	bra.uni 	LBB2_20;
LBB2_20:
	ld.u64 	%rd50, [%SP+64];
	ld.s32 	%rd51, [%SP+216];
	add.s64 	%rd52, %rd50, %rd51;
	mul.lo.s64 	%rd53, %rd52, 48;
	ld.u64 	%rd54, [%SP+56];
	ld.s32 	%rd55, [%SP+220];
	add.s64 	%rd56, %rd54, %rd55;
	add.s64 	%rd57, %rd53, %rd56;
	ld.u64 	%rd58, [%SP+96];
	shl.b64 	%rd59, %rd57, 2;
	add.s64 	%rd60, %rd58, %rd59;
	ld.shared.u32 	%r49, [%rd60];
	ld.u32 	%r50, [%SP+80];
	add.s32 	%r51, %r50, %r49;
	st.u32 	[%SP+80], %r51;
	bra.uni 	LBB2_21;
LBB2_21:
	ld.u32 	%r52, [%SP+220];
	add.s32 	%r53, %r52, 1;
	st.u32 	[%SP+220], %r53;
	bra.uni 	LBB2_19;
LBB2_22:
	bar.sync 	0;
	ld.u64 	%rd41, [%SP+64];
	ld.s32 	%rd42, [%SP+216];
	add.s64 	%rd43, %rd41, %rd42;
	mul.lo.s64 	%rd44, %rd43, 48;
	ld.u64 	%rd45, [%SP+56];
	add.s64 	%rd46, %rd44, %rd45;
	ld.u64 	%rd47, [%SP+96];
	shl.b64 	%rd48, %rd46, 2;
	add.s64 	%rd49, %rd47, %rd48;
	ld.u32 	%r46, [%SP+80];
	st.shared.u32 	[%rd49], %r46;
	bar.sync 	0;
	bra.uni 	LBB2_23;
LBB2_23:
	ld.u32 	%r47, [%SP+204];
	add.s32 	%r48, %r47, 1;
	st.u32 	[%SP+204], %r48;
	bra.uni 	LBB2_17;
LBB2_24:
	mov.u32 	%r24, 0;
	st.u32 	[%SP+80], %r24;
	mov.u32 	%r25, -8;
	st.u32 	[%SP+224], %r25;
	bra.uni 	LBB2_25;
LBB2_25:
	ld.u32 	%r26, [%SP+224];
	setp.gt.s32 	%p10, %r26, 8;
	@%p10 bra 	LBB2_28;
	bra.uni 	LBB2_26;
LBB2_26:
	ld.u64 	%rd32, [%SP+64];
	ld.s32 	%rd33, [%SP+224];
	add.s64 	%rd34, %rd32, %rd33;
	mul.lo.s64 	%rd35, %rd34, 48;
	ld.u64 	%rd36, [%SP+56];
	add.s64 	%rd37, %rd35, %rd36;
	ld.u64 	%rd38, [%SP+96];
	shl.b64 	%rd39, %rd37, 2;
	add.s64 	%rd40, %rd38, %rd39;
	ld.shared.u32 	%r34, [%rd40];
	ld.u32 	%r35, [%SP+80];
	add.s32 	%r36, %r35, %r34;
	st.u32 	[%SP+80], %r36;
	bra.uni 	LBB2_27;
LBB2_27:
	ld.u32 	%r37, [%SP+224];
	add.s32 	%r38, %r37, 1;
	st.u32 	[%SP+224], %r38;
	bra.uni 	LBB2_25;
LBB2_28:
	ld.u32 	%r27, [%SP+80];
	ld.u32 	%r28, [%SP+84];
	setp.ge.u32 	%p11, %r27, %r28;
	@%p11 bra 	LBB2_30;
	bra.uni 	LBB2_29;
LBB2_29:
	ld.u32 	%r29, [%SP+80];
	st.u32 	[%SP+84], %r29;
	ld.u32 	%r30, [%SP+168];
	add.s32 	%r31, %r30, 8;
	st.u32 	[%SP+88], %r31;
	bra.uni 	LBB2_30;
LBB2_30:
	bar.sync 	0;
	bra.uni 	LBB2_31;
LBB2_31:
	ld.u32 	%r32, [%SP+168];
	add.s32 	%r33, %r32, 1;
	st.u32 	[%SP+168], %r33;
	bra.uni 	LBB2_5;
LBB2_32:
	ld.s32 	%rd20, [%SP+52];
	ld.u64 	%rd21, [%SP+32];
	setp.ge.u64 	%p6, %rd20, %rd21;
	mov.pred 	%p5, 0;
	mov.pred 	%p14, %p5;
	@%p6 bra 	LBB2_34;
	bra.uni 	LBB2_33;
LBB2_33:
	ld.s32 	%rd22, [%SP+48];
	ld.u64 	%rd23, [%SP+24];
	setp.lt.u64 	%p1, %rd22, %rd23;
	mov.pred 	%p14, %p1;
	bra.uni 	LBB2_34;
LBB2_34:
	mov.pred 	%p2, %p14;
	@!%p2 bra 	LBB2_36;
	bra.uni 	LBB2_35;
LBB2_35:
	ld.s32 	%rd24, [%SP+52];
	ld.u64 	%rd25, [%SP+24];
	mul.lo.s64 	%rd26, %rd24, %rd25;
	ld.s32 	%rd27, [%SP+48];
	add.s64 	%rd28, %rd26, %rd27;
	ld.u64 	%rd29, [%SP+16];
	shl.b64 	%rd30, %rd28, 2;
	add.s64 	%rd31, %rd29, %rd30;
	ld.u32 	%r11, [%SP+88];
	st.global.u32 	[%rd31], %r11;
	bra.uni 	LBB2_36;
LBB2_36:
	ret;

}
	// .weak	_D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm()
{
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<2>;

	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r3, %r1, %r2;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	cvt.u64.u32 	%rd1, %r5;
	st.param.b64 	[func_retval0+0], %rd1;
	ret;

}
	// .weak	_D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm()
{
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<2>;

	mov.u32 	%r1, %ctaid.y;
	mov.u32 	%r2, %ntid.y;
	mul.lo.s32 	%r3, %r1, %r2;
	mov.u32 	%r4, %tid.y;
	add.s32 	%r5, %r3, %r4;
	cvt.u64.u32 	%rd1, %r5;
	st.param.b64 	[func_retval0+0], %rd1;
	ret;

}
	// .weak	_D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11SharedIndex__T1xZQdFNaNbNdNiZm()
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<2>;

	mov.u32 	%r1, %tid.x;
	cvt.u64.u32 	%rd1, %r1;
	st.param.b64 	[func_retval0+0], %rd1;
	ret;

}
	// .weak	_D8dcompute3std5index11SharedIndex__T1yZQdFNaNbNdNiZm
.weak .func  (.param .b64 func_retval0) _D8dcompute3std5index11SharedIndex__T1yZQdFNaNbNdNiZm()
{
	.reg .b32 	%r<2>;
	.reg .b64 	%rd<2>;

	mov.u32 	%r1, %tid.y;
	cvt.u64.u32 	%rd1, %r1;
	st.param.b64 	[func_retval0+0], %rd1;
	ret;

}
	// .weak	_D8dcompute3std6memory__T19sharedStaticReserveHTG1152kVAyaa5_6469666630Vmi1152ZQCcFNbNiZS3ldcQDn__T7PointerVEQuQEf9AddrSpacei2TkZQBe
.weak .func _D8dcompute3std6memory__T19sharedStaticReserveHTG1152kVAyaa5_6469666630Vmi1152ZQCcFNbNiZS3ldcQDn__T7PointerVEQuQEf9AddrSpacei2TkZQBe(
	.param .b64 _D8dcompute3std6memory__T19sharedStaticReserveHTG1152kVAyaa5_6469666630Vmi1152ZQCcFNbNiZS3ldcQDn__T7PointerVEQuQEf9AddrSpacei2TkZQBe_param_0
)
{
	.local .align 8 .b8 	__local_depot7[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b16 	%rs<9>;
	.reg .b64 	%rd<5>;

	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_D8dcompute3std6memory__T19sharedStaticReserveHTG1152kVAyaa5_6469666630Vmi1152ZQCcFNbNiZS3ldcQDn__T7PointerVEQuQEf9AddrSpacei2TkZQBe_param_0];
	mov.u64 	%rd2, diff0;
	st.u64 	[%SP+0], %rd2;
	add.u64 	%rd3, %SP, 0;
	st.u64 	[%SP+8], %rd3;
	ld.u64 	%rd4, [%SP+8];
	ld.u8 	%rs1, [%rd4+7];
	st.u8 	[%rd1+7], %rs1;
	ld.u8 	%rs2, [%rd4+6];
	st.u8 	[%rd1+6], %rs2;
	ld.u8 	%rs3, [%rd4+5];
	st.u8 	[%rd1+5], %rs3;
	ld.u8 	%rs4, [%rd4+4];
	st.u8 	[%rd1+4], %rs4;
	ld.u8 	%rs5, [%rd4+3];
	st.u8 	[%rd1+3], %rs5;
	ld.u8 	%rs6, [%rd4+2];
	st.u8 	[%rd1+2], %rs6;
	ld.u8 	%rs7, [%rd4+1];
	st.u8 	[%rd1+1], %rs7;
	ld.u8 	%rs8, [%rd4];
	st.u8 	[%rd1], %rs8;
	ret;

}
	// .globl	_D7dispmap8printIntFkZv
.visible .func _D7dispmap8printIntFkZv(
	.param .b32 _D7dispmap8printIntFkZv_param_0
)
{
	.local .align 8 .b8 	__local_depot8[56];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<5>;

	mov.u64 	%SPL, __local_depot8;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r1, [_D7dispmap8printIntFkZv_param_0];
	st.u32 	[%SP+48], %r1;
	ld.u32 	%r2, [%SP+48];
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r2;
	mov.u64 	%rd3, str;
	cvta.const.u64 	%rd4, %rd3;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r3, [retval0+0];
	} // callseq 12
	ret;

}
	// .globl	_D7dispmap10printFloatFfZv
.visible .func _D7dispmap10printFloatFfZv(
	.param .b32 _D7dispmap10printFloatFfZv_param_0
)
{
	.local .align 8 .b8 	__local_depot9[56];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<5>;

	mov.u64 	%SPL, __local_depot9;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f1, [_D7dispmap10printFloatFfZv_param_0];
	st.f32 	[%SP+48], %f1;
	ld.f32 	%f2, [%SP+48];
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.f32 	[%rd2], %f2;
	mov.u64 	%rd3, str1;
	cvta.const.u64 	%rd4, %rd3;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r1, [retval0+0];
	} // callseq 13
	ret;

}
	// .weak	_D8dcompute3std6memory__T4ItoaVki1152ZQnFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T4ItoaVki1152ZQnFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 4;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T4ItoaVki115ZQmFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T4ItoaVki115ZQmFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 3;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str2;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T4ItoaVki11ZQlFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T4ItoaVki11ZQlFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 2;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str3;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T4ItoaVki1ZQkFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T4ItoaVki1ZQkFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 1;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str4;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T5DigitVmi1ZQlFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T5DigitVmi1ZQlFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 1;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str4;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T5DigitVmi5ZQlFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T5DigitVmi5ZQlFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 1;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str5;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T5DigitVmi2ZQlFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T5DigitVmi2ZQlFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 1;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str6;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .weak	_D8dcompute3std6memory__T8llvmTypeTkZQmFNaNbNiNfZyAa
.weak .func  (.param .align 8 .b8 func_retval0[16]) _D8dcompute3std6memory__T8llvmTypeTkZQmFNaNbNiNfZyAa()
{
	.reg .b64 	%rd<4>;

	mov.u64 	%rd1, 3;
	st.param.b64 	[func_retval0+0], %rd1;
	mov.u64 	%rd2, _$_str7;
	cvta.global.u64 	%rd3, %rd2;
	st.param.b64 	[func_retval0+8], %rd3;
	ret;

}
	// .globl	_D9bilateral6__expfFfZf
.visible .func  (.param .b32 func_retval0) _D9bilateral6__expfFfZf(
	.param .b32 _D9bilateral6__expfFfZf_param_0
)
{
	.local .align 4 .b8 	__local_depot18[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .f32 	%f<12>;

	mov.u64 	%SPL, __local_depot18;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f1, [_D9bilateral6__expfFfZf_param_0];
	st.f32 	[%SP+0], %f1;
	mov.u32 	%r1, 2143289344;
	st.u32 	[%SP+4], %r1;
	mov.u32 	%r2, 0;
	st.u32 	[%SP+8], %r2;
	st.u32 	[%SP+12], %r2;
	mov.u32 	%r3, 1065353216;
	st.u32 	[%SP+4], %r3;
	bra.uni 	LBB18_1;
LBB18_1:
	ld.f32 	%f2, [%SP+4];
	ld.f32 	%f3, [%SP+8];
	add.rn.f32 	%f4, %f3, %f2;
	st.f32 	[%SP+8], %f4;
	ld.f32 	%f5, [%SP+0];
	ld.u32 	%r4, [%SP+12];
	add.s32 	%r5, %r4, 1;
	st.u32 	[%SP+12], %r5;
	ld.u32 	%r6, [%SP+12];
	cvt.rn.f32.s32 	%f6, %r6;
	div.rn.f32 	%f7, %f5, %f6;
	ld.f32 	%f8, [%SP+4];
	mul.rn.f32 	%f9, %f8, %f7;
	st.f32 	[%SP+4], %f9;
	bra.uni 	LBB18_2;
LBB18_2:
	ld.f32 	%f10, [%SP+4];
	setp.gt.f32 	%p1, %f10, 0f3C23D70A;
	@%p1 bra 	LBB18_1;
	bra.uni 	LBB18_3;
LBB18_3:
	ld.f32 	%f11, [%SP+8];
	st.param.f32 	[func_retval0+0], %f11;
	ret;

}
	// .globl	_D9bilateral9saturatefFfZf
.visible .func  (.param .b32 func_retval0) _D9bilateral9saturatefFfZf(
	.param .b32 _D9bilateral9saturatefFfZf_param_0
)
{
	.local .align 4 .b8 	__local_depot19[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<3>;
	.reg .f32 	%f<7>;

	mov.u64 	%SPL, __local_depot19;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f1, [_D9bilateral9saturatefFfZf_param_0];
	st.f32 	[%SP+0], %f1;
	ld.f32 	%f2, [%SP+0];
	setp.gtu.f32 	%p1, %f2, 0f00000000;
	@%p1 bra 	LBB19_2;
	bra.uni 	LBB19_1;
LBB19_1:
	mov.f32 	%f6, 0f00000000;
	st.param.f32 	[func_retval0+0], %f6;
	ret;
LBB19_2:
	ld.f32 	%f3, [%SP+0];
	setp.ltu.f32 	%p2, %f3, 0f3F800000;
	@%p2 bra 	LBB19_4;
	bra.uni 	LBB19_3;
LBB19_3:
	mov.f32 	%f5, 0f3F800000;
	st.param.f32 	[func_retval0+0], %f5;
	ret;
LBB19_4:
	ld.f32 	%f4, [%SP+0];
	st.param.f32 	[func_retval0+0], %f4;
	ret;

}
	// .globl	_D9bilateral12euclideanLenFSQBa6float4QlfZf
.visible .func  (.param .b32 func_retval0) _D9bilateral12euclideanLenFSQBa6float4QlfZf(
	.param .align 4 .b8 _D9bilateral12euclideanLenFSQBa6float4QlfZf_param_0[16],
	.param .align 4 .b8 _D9bilateral12euclideanLenFSQBa6float4QlfZf_param_1[16],
	.param .b32 _D9bilateral12euclideanLenFSQBa6float4QlfZf_param_2
)
{
	.local .align 8 .b8 	__local_depot20[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<32>;
	.reg .b64 	%rd<5>;

	mov.u64 	%SPL, __local_depot20;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f8, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_1+12];
	ld.param.f32 	%f7, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_1+8];
	ld.param.f32 	%f6, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_1+4];
	ld.param.f32 	%f5, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_1];
	ld.param.f32 	%f4, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_0+12];
	ld.param.f32 	%f3, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_0+8];
	ld.param.f32 	%f2, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_0+4];
	ld.param.f32 	%f1, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_0];
	ld.param.f32 	%f9, [_D9bilateral12euclideanLenFSQBa6float4QlfZf_param_2];
	add.u64 	%rd1, %SP, 0;
	or.b64  	%rd2, %rd1, 4;
	st.f32 	[%rd2], %f2;
	st.f32 	[%SP+12], %f4;
	st.f32 	[%SP+8], %f3;
	st.f32 	[%SP+0], %f1;
	add.u64 	%rd3, %SP, 16;
	or.b64  	%rd4, %rd3, 4;
	st.f32 	[%rd4], %f6;
	st.f32 	[%SP+28], %f8;
	st.f32 	[%SP+24], %f7;
	st.f32 	[%SP+16], %f5;
	st.f32 	[%SP+32], %f9;
	ld.f32 	%f10, [%SP+16];
	ld.f32 	%f11, [%SP+0];
	sub.rn.f32 	%f12, %f10, %f11;
	mul.rn.f32 	%f13, %f12, %f12;
	ld.f32 	%f14, [%rd4];
	ld.f32 	%f15, [%rd2];
	sub.rn.f32 	%f16, %f14, %f15;
	mul.rn.f32 	%f17, %f16, %f16;
	add.rn.f32 	%f18, %f13, %f17;
	ld.f32 	%f19, [%SP+24];
	ld.f32 	%f20, [%SP+8];
	sub.rn.f32 	%f21, %f19, %f20;
	mul.rn.f32 	%f22, %f21, %f21;
	add.rn.f32 	%f23, %f18, %f22;
	st.f32 	[%SP+36], %f23;
	ld.f32 	%f24, [%SP+36];
	neg.f32 	%f25, %f24;
	ld.f32 	%f26, [%SP+32];
	add.rn.f32 	%f27, %f26, %f26;
	mul.rn.f32 	%f28, %f27, %f26;
	div.rn.f32 	%f29, %f25, %f28;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f29;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral6__expfFfZf, 
	(
	param0
	);
	ld.param.f32 	%f30, [retval0+0];
	} // callseq 14
	st.param.f32 	[func_retval0+0], %f30;
	ret;

}
	// .globl	_D9bilateral14rgbaFloatToIntFSQBc6float4Zk
.visible .func  (.param .b32 func_retval0) _D9bilateral14rgbaFloatToIntFSQBc6float4Zk(
	.param .align 4 .b8 _D9bilateral14rgbaFloatToIntFSQBc6float4Zk_param_0[16]
)
{
	.local .align 8 .b8 	__local_depot21[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<11>;
	.reg .f32 	%f<33>;
	.reg .b64 	%rd<3>;

	mov.u64 	%SPL, __local_depot21;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f4, [_D9bilateral14rgbaFloatToIntFSQBc6float4Zk_param_0+12];
	ld.param.f32 	%f3, [_D9bilateral14rgbaFloatToIntFSQBc6float4Zk_param_0+8];
	ld.param.f32 	%f2, [_D9bilateral14rgbaFloatToIntFSQBc6float4Zk_param_0+4];
	ld.param.f32 	%f1, [_D9bilateral14rgbaFloatToIntFSQBc6float4Zk_param_0];
	add.u64 	%rd1, %SP, 0;
	or.b64  	%rd2, %rd1, 4;
	st.f32 	[%rd2], %f2;
	st.f32 	[%SP+12], %f4;
	st.f32 	[%SP+8], %f3;
	st.f32 	[%SP+0], %f1;
	ld.f32 	%f5, [%SP+0];
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f5;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral__T3absTfZQhFNaNbNiNefZf, 
	(
	param0
	);
	ld.param.f32 	%f6, [retval0+0];
	} // callseq 15
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f6;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral9saturatefFfZf, 
	(
	param0
	);
	ld.param.f32 	%f8, [retval0+0];
	} // callseq 16
	st.f32 	[%SP+0], %f8;
	ld.f32 	%f10, [%rd2];
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f10;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral__T3absTfZQhFNaNbNiNefZf, 
	(
	param0
	);
	ld.param.f32 	%f11, [retval0+0];
	} // callseq 17
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f11;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral9saturatefFfZf, 
	(
	param0
	);
	ld.param.f32 	%f13, [retval0+0];
	} // callseq 18
	st.f32 	[%rd2], %f13;
	ld.f32 	%f15, [%SP+8];
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f15;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral__T3absTfZQhFNaNbNiNefZf, 
	(
	param0
	);
	ld.param.f32 	%f16, [retval0+0];
	} // callseq 19
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f16;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral9saturatefFfZf, 
	(
	param0
	);
	ld.param.f32 	%f18, [retval0+0];
	} // callseq 20
	st.f32 	[%SP+8], %f18;
	ld.f32 	%f20, [%SP+12];
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f20;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral__T3absTfZQhFNaNbNiNefZf, 
	(
	param0
	);
	ld.param.f32 	%f21, [retval0+0];
	} // callseq 21
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f21;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral9saturatefFfZf, 
	(
	param0
	);
	ld.param.f32 	%f23, [retval0+0];
	} // callseq 22
	st.f32 	[%SP+12], %f23;
	ld.f32 	%f25, [%SP+12];
	mul.rn.f32 	%f26, %f25, 0f437F0000;
	cvt.rzi.u32.f32 	%r1, %f26;
	shl.b32 	%r2, %r1, 24;
	ld.f32 	%f27, [%SP+8];
	mul.rn.f32 	%f28, %f27, 0f437F0000;
	cvt.rzi.u32.f32 	%r3, %f28;
	shl.b32 	%r4, %r3, 16;
	or.b32  	%r5, %r2, %r4;
	ld.f32 	%f29, [%rd2];
	mul.rn.f32 	%f30, %f29, 0f437F0000;
	cvt.rzi.u32.f32 	%r6, %f30;
	shl.b32 	%r7, %r6, 8;
	or.b32  	%r8, %r5, %r7;
	ld.f32 	%f31, [%SP+0];
	mul.rn.f32 	%f32, %f31, 0f437F0000;
	cvt.rzi.u32.f32 	%r9, %f32;
	or.b32  	%r10, %r8, %r9;
	st.param.b32 	[func_retval0+0], %r10;
	ret;

}
	// .weak	_D9bilateral__T3absTfZQhFNaNbNiNefZf
.weak .func  (.param .b32 func_retval0) _D9bilateral__T3absTfZQhFNaNbNiNefZf(
	.param .b32 _D9bilateral__T3absTfZQhFNaNbNiNefZf_param_0
)
{
	.local .align 8 .b8 	__local_depot22[24];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .f32 	%f<6>;
	.reg .b64 	%rd<4>;

	mov.u64 	%SPL, __local_depot22;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f1, [_D9bilateral__T3absTfZQhFNaNbNiNefZf_param_0];
	st.f32 	[%SP+0], %f1;
	ld.f32 	%f2, [%SP+0];
	setp.ltu.f32 	%p1, %f2, 0f00000000;
	@%p1 bra 	LBB22_2;
	bra.uni 	LBB22_1;
LBB22_1:
	add.u64 	%rd2, %SP, 0;
	st.u64 	[%SP+8], %rd2;
	bra.uni 	LBB22_3;
LBB22_2:
	ld.f32 	%f3, [%SP+0];
	neg.f32 	%f4, %f3;
	st.f32 	[%SP+16], %f4;
	add.u64 	%rd1, %SP, 16;
	st.u64 	[%SP+8], %rd1;
	bra.uni 	LBB22_3;
LBB22_3:
	ld.u64 	%rd3, [%SP+8];
	ld.f32 	%f5, [%rd3];
	st.param.f32 	[func_retval0+0], %f5;
	ret;

}
	// .globl	_D9bilateral14rgbaIntToFloatFkZSQBe6float4
.visible .func _D9bilateral14rgbaIntToFloatFkZSQBe6float4(
	.param .b64 _D9bilateral14rgbaIntToFloatFkZSQBe6float4_param_0,
	.param .b32 _D9bilateral14rgbaIntToFloatFkZSQBe6float4_param_1
)
{
	.local .align 4 .b8 	__local_depot23[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b16 	%rs<17>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<9>;
	.reg .b64 	%rd<8>;

	mov.u64 	%SPL, __local_depot23;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r1, [_D9bilateral14rgbaIntToFloatFkZSQBe6float4_param_1];
	ld.param.u64 	%rd1, [_D9bilateral14rgbaIntToFloatFkZSQBe6float4_param_0];
	st.u32 	[%SP+0], %r1;
	mov.u64 	%rd2, _D9bilateral6float46__initZ;
	cvta.global.u64 	%rd3, %rd2;
	ld.u8 	%rs1, [%rd3+15];
	st.u8 	[%rd1+15], %rs1;
	ld.u8 	%rs2, [%rd3+14];
	st.u8 	[%rd1+14], %rs2;
	ld.u8 	%rs3, [%rd3+13];
	st.u8 	[%rd1+13], %rs3;
	ld.u8 	%rs4, [%rd3+12];
	st.u8 	[%rd1+12], %rs4;
	ld.u8 	%rs5, [%rd3+11];
	st.u8 	[%rd1+11], %rs5;
	ld.u8 	%rs6, [%rd3+10];
	st.u8 	[%rd1+10], %rs6;
	ld.u8 	%rs7, [%rd3+9];
	st.u8 	[%rd1+9], %rs7;
	ld.u8 	%rs8, [%rd3+8];
	st.u8 	[%rd1+8], %rs8;
	ld.u8 	%rs9, [%rd3+7];
	st.u8 	[%rd1+7], %rs9;
	ld.u8 	%rs10, [%rd3+6];
	st.u8 	[%rd1+6], %rs10;
	ld.u8 	%rs11, [%rd3+5];
	st.u8 	[%rd1+5], %rs11;
	ld.u8 	%rs12, [%rd3+4];
	st.u8 	[%rd1+4], %rs12;
	ld.u8 	%rs13, [%rd3+3];
	st.u8 	[%rd1+3], %rs13;
	ld.u8 	%rs14, [%rd3+2];
	st.u8 	[%rd1+2], %rs14;
	ld.u8 	%rs15, [%rd3+1];
	st.u8 	[%rd1+1], %rs15;
	ld.u8 	%rs16, [%rd3];
	st.u8 	[%rd1], %rs16;
	ld.u8 	%r2, [%SP+0];
	cvt.rn.f32.u32 	%f1, %r2;
	mul.rn.f32 	%f2, %f1, 0f3B808081;
	st.f32 	[%rd1], %f2;
	add.u64 	%rd4, %SP, 0;
	or.b64  	%rd5, %rd4, 1;
	ld.u8 	%r3, [%rd5];
	cvt.rn.f32.u32 	%f3, %r3;
	mul.rn.f32 	%f4, %f3, 0f3B808081;
	st.f32 	[%rd1+4], %f4;
	or.b64  	%rd6, %rd4, 2;
	ld.u8 	%r4, [%rd6];
	cvt.rn.f32.u32 	%f5, %r4;
	mul.rn.f32 	%f6, %f5, 0f3B808081;
	st.f32 	[%rd1+8], %f6;
	or.b64  	%rd7, %rd4, 3;
	ld.u8 	%r5, [%rd7];
	cvt.rn.f32.u32 	%f7, %r5;
	mul.rn.f32 	%f8, %f7, 0f3B808081;
	st.f32 	[%rd1+12], %f8;
	ret;

}
	// .globl	_D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv
.visible .entry _D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv(
	.param .u64 _D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_0,
	.param .u64 _D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_1,
	.param .u64 _D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_2,
	.param .u64 _D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_3,
	.param .f32 _D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_4,
	.param .u32 _D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_5
)
{
	.local .align 8 .b8 	__local_depot24[472];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<42>;
	.reg .f32 	%f<48>;
	.reg .b64 	%rd<67>;

	mov.u64 	%SPL, __local_depot24;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r1, [_D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_5];
	ld.param.f32 	%f1, [_D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_4];
	ld.param.u64 	%rd5, [_D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_3];
	ld.param.u64 	%rd4, [_D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_2];
	ld.param.u64 	%rd3, [_D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_1];
	ld.param.u64 	%rd2, [_D9bilateral16bilateral_filterFmS3ldc8dcompute__T7PointerVEQBaQz9AddrSpacei1TiZQBemmfiZv_param_0];
	st.u64 	[%SP+0], %rd2;
	st.u64 	[%SP+8], %rd3;
	st.u64 	[%SP+16], %rd4;
	st.u64 	[%SP+24], %rd5;
	st.f32 	[%SP+32], %f1;
	st.u32 	[%SP+36], %r1;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11GlobalIndex__T1xZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd6, [retval0+0];
	} // callseq 23
	st.u32 	[%SP+40], %rd6;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 retval0;
	call.uni (retval0), 
	_D8dcompute3std5index11GlobalIndex__T1yZQdFNaNbNdNiZm, 
	(
	);
	ld.param.b64 	%rd8, [retval0+0];
	} // callseq 24
	st.u32 	[%SP+44], %rd8;
	ld.s32 	%rd10, [%SP+40];
	ld.u64 	%rd11, [%SP+16];
	setp.ge.u64 	%p4, %rd10, %rd11;
	mov.pred 	%p3, -1;
	mov.pred 	%p9, %p3;
	@%p4 bra 	LBB24_2;
	bra.uni 	LBB24_1;
LBB24_1:
	ld.s32 	%rd12, [%SP+44];
	ld.u64 	%rd13, [%SP+24];
	setp.ge.u64 	%p1, %rd12, %rd13;
	mov.pred 	%p9, %p1;
	bra.uni 	LBB24_2;
LBB24_2:
	mov.pred 	%p2, %p9;
	@!%p2 bra 	LBB24_4;
	bra.uni 	LBB24_3;
LBB24_3:
	ret;
LBB24_4:
	add.u64 	%rd1, %SP, 48;
	mov.u64 	%rd14, 0;
	st.u64 	[%SP+304], %rd14;
	bra.uni 	LBB24_5;
LBB24_5:
	ld.u64 	%rd15, [%SP+304];
	setp.eq.s64 	%p5, %rd15, 64;
	@%p5 bra 	LBB24_7;
	bra.uni 	LBB24_6;
LBB24_6:
	ld.u64 	%rd63, [%SP+304];
	shl.b64 	%rd64, %rd63, 2;
	add.s64 	%rd65, %rd1, %rd64;
	mov.u32 	%r41, 2143289344;
	st.u32 	[%rd65], %r41;
	add.s64 	%rd66, %rd63, 1;
	st.u64 	[%SP+304], %rd66;
	bra.uni 	LBB24_5;
LBB24_7:
	add.u64 	%rd16, %SP, 48;
	st.u64 	[%SP+312], %rd16;
	mov.u32 	%r2, 0;
	st.u32 	[%SP+320], %r2;
	bra.uni 	LBB24_8;
LBB24_8:
	ld.u32 	%r3, [%SP+36];
	shl.b32 	%r4, %r3, 1;
	or.b32  	%r5, %r4, 1;
	ld.u32 	%r6, [%SP+320];
	setp.ge.s32 	%p6, %r6, %r5;
	@%p6 bra 	LBB24_11;
	bra.uni 	LBB24_9;
LBB24_9:
	ld.u32 	%r36, [%SP+320];
	ld.u32 	%r37, [%SP+36];
	sub.s32 	%r38, %r36, %r37;
	cvt.rn.f32.s32 	%f38, %r38;
	st.f32 	[%SP+324], %f38;
	ld.s32 	%rd59, [%SP+320];
	ld.u64 	%rd60, [%SP+312];
	shl.b64 	%rd61, %rd59, 2;
	add.s64 	%rd62, %rd60, %rd61;
	ld.f32 	%f39, [%SP+324];
	mul.rn.f32 	%f40, %f39, %f39;
	neg.f32 	%f41, %f40;
	ld.f32 	%f42, [%SP+32];
	add.rn.f32 	%f43, %f42, %f42;
	mul.rn.f32 	%f44, %f43, %f42;
	div.rn.f32 	%f45, %f41, %f44;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.f32 	[param0+0], %f45;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral6__expfFfZf, 
	(
	param0
	);
	ld.param.f32 	%f46, [retval0+0];
	} // callseq 30
	st.f32 	[%rd62], %f46;
	bra.uni 	LBB24_10;
LBB24_10:
	ld.u32 	%r39, [%SP+320];
	add.s32 	%r40, %r39, 1;
	st.u32 	[%SP+320], %r40;
	bra.uni 	LBB24_8;
LBB24_11:
	mov.u32 	%r7, 0;
	st.u32 	[%SP+328], %r7;
	mov.u32 	%r8, 2143289344;
	st.u32 	[%SP+332], %r8;
	st.u32 	[%SP+336], %r7;
	add.u64 	%rd17, %SP, 336;
	or.b64  	%rd18, %rd17, 4;
	st.u32 	[%rd18], %r7;
	st.u32 	[%SP+344], %r7;
	st.u32 	[%SP+348], %r7;
	ld.u64 	%rd19, [%SP+0];
	ld.u32 	%r9, [%SP+40];
	ld.u32 	%r10, [%SP+44];
	tex.2d.v4.f32.s32 	{%f2, %f3, %f4, %f5}, [%rd19, {%r9, %r10}];
	mov.u64 	%rd20, 0;
	st.u64 	[%SP+376], %rd20;
	st.u64 	[%SP+368], %rd20;
	st.f32 	[%SP+368], %f2;
	add.u64 	%rd21, %SP, 368;
	or.b64  	%rd22, %rd21, 4;
	st.f32 	[%rd22], %f3;
	st.f32 	[%SP+376], %f4;
	st.f32 	[%SP+380], %f5;
	ld.u64 	%rd23, [%SP+376];
	st.u64 	[%SP+360], %rd23;
	ld.u64 	%rd24, [%SP+368];
	st.u64 	[%SP+352], %rd24;
	ld.u32 	%r11, [%SP+36];
	neg.s32 	%r12, %r11;
	st.u32 	[%SP+384], %r12;
	bra.uni 	LBB24_12;
LBB24_12:
	ld.u32 	%r13, [%SP+384];
	ld.u32 	%r14, [%SP+36];
	setp.gt.s32 	%p7, %r13, %r14;
	@%p7 bra 	LBB24_19;
	bra.uni 	LBB24_13;
LBB24_13:
	ld.u32 	%r17, [%SP+36];
	neg.s32 	%r18, %r17;
	st.u32 	[%SP+388], %r18;
	bra.uni 	LBB24_14;
LBB24_14:
	ld.u32 	%r19, [%SP+388];
	ld.u32 	%r20, [%SP+36];
	setp.gt.s32 	%p8, %r19, %r20;
	@%p8 bra 	LBB24_17;
	bra.uni 	LBB24_15;
LBB24_15:
	ld.u64 	%rd36, [%SP+0];
	ld.u32 	%r23, [%SP+40];
	ld.u32 	%r24, [%SP+388];
	add.s32 	%r25, %r23, %r24;
	ld.u32 	%r26, [%SP+44];
	ld.u32 	%r27, [%SP+384];
	add.s32 	%r28, %r26, %r27;
	tex.2d.v4.f32.s32 	{%f11, %f12, %f13, %f14}, [%rd36, {%r25, %r28}];
	mov.u64 	%rd37, 0;
	st.u64 	[%SP+416], %rd37;
	st.u64 	[%SP+408], %rd37;
	st.f32 	[%SP+408], %f11;
	add.u64 	%rd38, %SP, 408;
	or.b64  	%rd39, %rd38, 4;
	st.f32 	[%rd39], %f12;
	st.f32 	[%SP+416], %f13;
	st.f32 	[%SP+420], %f14;
	ld.u64 	%rd40, [%SP+416];
	st.u64 	[%SP+400], %rd40;
	ld.u64 	%rd41, [%SP+408];
	st.u64 	[%SP+392], %rd41;
	ld.u32 	%r29, [%SP+384];
	ld.u32 	%r30, [%SP+36];
	add.s32 	%r31, %r29, %r30;
	cvt.s64.s32 	%rd42, %r31;
	ld.u64 	%rd43, [%SP+312];
	shl.b64 	%rd44, %rd42, 2;
	add.s64 	%rd45, %rd43, %rd44;
	ld.f32 	%f15, [%rd45];
	ld.u32 	%r32, [%SP+388];
	add.s32 	%r33, %r32, %r30;
	cvt.s64.s32 	%rd46, %r33;
	shl.b64 	%rd47, %rd46, 2;
	add.s64 	%rd48, %rd43, %rd47;
	ld.f32 	%f16, [%rd48];
	mul.rn.f32 	%f17, %f15, %f16;
	add.u64 	%rd49, %SP, 392;
	or.b64  	%rd50, %rd49, 4;
	ld.f32 	%f18, [%rd50];
	ld.f32 	%f19, [%SP+404];
	ld.f32 	%f20, [%SP+400];
	ld.f32 	%f21, [%SP+392];
	add.u64 	%rd51, %SP, 352;
	or.b64  	%rd52, %rd51, 4;
	ld.f32 	%f22, [%rd52];
	ld.f32 	%f23, [%SP+364];
	ld.f32 	%f24, [%SP+360];
	ld.f32 	%f25, [%SP+352];
	ld.f32 	%f26, [%SP+32];
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .align 4 .b8 param0[16];
	st.param.f32 	[param0+0], %f21;
	st.param.f32 	[param0+4], %f18;
	st.param.f32 	[param0+8], %f20;
	st.param.f32 	[param0+12], %f19;
	.param .align 4 .b8 param1[16];
	st.param.f32 	[param1+0], %f25;
	st.param.f32 	[param1+4], %f22;
	st.param.f32 	[param1+8], %f24;
	st.param.f32 	[param1+12], %f23;
	.param .b32 param2;
	st.param.f32 	[param2+0], %f26;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral12euclideanLenFSQBa6float4QlfZf, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.f32 	%f27, [retval0+0];
	} // callseq 27
	mul.rn.f32 	%f29, %f17, %f27;
	st.f32 	[%SP+332], %f29;
	ld.f32 	%f30, [%SP+332];
	add.u64 	%rd53, %SP, 440;
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd53;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd49;
	.param .b32 param2;
	st.param.f32 	[param2+0], %f30;
	call.uni 
	_D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 28
	or.b64  	%rd54, %rd53, 4;
	ld.f32 	%f31, [%rd54];
	ld.f32 	%f32, [%SP+452];
	ld.f32 	%f33, [%SP+448];
	ld.f32 	%f34, [%SP+440];
	add.u64 	%rd55, %SP, 424;
	add.u64 	%rd56, %SP, 336;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd55;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd56;
	.param .align 4 .b8 param2[16];
	st.param.f32 	[param2+0], %f34;
	st.param.f32 	[param2+4], %f31;
	st.param.f32 	[param2+8], %f33;
	st.param.f32 	[param2+12], %f32;
	call.uni 
	_D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 29
	ld.u64 	%rd57, [%SP+432];
	st.u64 	[%SP+344], %rd57;
	ld.u64 	%rd58, [%SP+424];
	st.u64 	[%SP+336], %rd58;
	ld.f32 	%f35, [%SP+332];
	ld.f32 	%f36, [%SP+328];
	add.rn.f32 	%f37, %f36, %f35;
	st.f32 	[%SP+328], %f37;
	bra.uni 	LBB24_16;
LBB24_16:
	ld.u32 	%r34, [%SP+388];
	add.s32 	%r35, %r34, 1;
	st.u32 	[%SP+388], %r35;
	bra.uni 	LBB24_14;
LBB24_17:
	bra.uni 	LBB24_18;
LBB24_18:
	ld.u32 	%r21, [%SP+384];
	add.s32 	%r22, %r21, 1;
	st.u32 	[%SP+384], %r22;
	bra.uni 	LBB24_12;
LBB24_19:
	ld.s32 	%rd25, [%SP+44];
	ld.u64 	%rd26, [%SP+16];
	mul.lo.s64 	%rd27, %rd25, %rd26;
	ld.s32 	%rd28, [%SP+40];
	add.s64 	%rd29, %rd27, %rd28;
	ld.u64 	%rd30, [%SP+8];
	shl.b64 	%rd31, %rd29, 2;
	add.s64 	%rd32, %rd30, %rd31;
	ld.f32 	%f6, [%SP+328];
	add.u64 	%rd33, %SP, 456;
	add.u64 	%rd34, %SP, 336;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd33;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.f32 	[param2+0], %f6;
	call.uni 
	_D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 25
	or.b64  	%rd35, %rd33, 4;
	ld.f32 	%f7, [%rd35];
	ld.f32 	%f8, [%SP+468];
	ld.f32 	%f9, [%SP+464];
	ld.f32 	%f10, [%SP+456];
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .align 4 .b8 param0[16];
	st.param.f32 	[param0+0], %f10;
	st.param.f32 	[param0+4], %f7;
	st.param.f32 	[param0+8], %f9;
	st.param.f32 	[param0+12], %f8;
	.param .b32 retval0;
	call.uni (retval0), 
	_D9bilateral14rgbaFloatToIntFSQBc6float4Zk, 
	(
	param0
	);
	ld.param.b32 	%r15, [retval0+0];
	} // callseq 26
	st.global.u32 	[%rd32], %r15;
	ret;

}
	// .weak	_D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi
.weak .func _D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi(
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_0,
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_1,
	.param .align 4 .b8 _D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_2[16]
)
{
	.local .align 8 .b8 	__local_depot25[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<5>;

	mov.u64 	%SPL, __local_depot25;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f4, [_D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_2+12];
	ld.param.f32 	%f3, [_D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_2+8];
	ld.param.f32 	%f2, [_D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_2+4];
	ld.param.f32 	%f1, [_D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_2];
	ld.param.u64 	%rd2, [_D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_1];
	ld.param.u64 	%rd1, [_D9bilateral6float4__T8opBinaryVAyaa1_2bZQtMFNaNbNiNfSQCaQBtZQi_param_0];
	add.u64 	%rd3, %SP, 0;
	or.b64  	%rd4, %rd3, 4;
	st.f32 	[%rd4], %f2;
	st.f32 	[%SP+12], %f4;
	st.f32 	[%SP+8], %f3;
	st.f32 	[%SP+0], %f1;
	ld.f32 	%f5, [%rd2];
	ld.f32 	%f6, [%SP+0];
	add.rn.f32 	%f7, %f5, %f6;
	st.f32 	[%rd1], %f7;
	ld.f32 	%f8, [%rd2+4];
	ld.f32 	%f9, [%rd4];
	add.rn.f32 	%f10, %f8, %f9;
	st.f32 	[%rd1+4], %f10;
	ld.f32 	%f11, [%rd2+8];
	ld.f32 	%f12, [%SP+8];
	add.rn.f32 	%f13, %f11, %f12;
	st.f32 	[%rd1+8], %f13;
	ld.f32 	%f14, [%rd2+12];
	ld.f32 	%f15, [%SP+12];
	add.rn.f32 	%f16, %f14, %f15;
	st.f32 	[%rd1+12], %f16;
	ret;

}
	// .weak	_D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv
.weak .func _D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv(
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_0,
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_1,
	.param .b32 _D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_2
)
{
	.local .align 4 .b8 	__local_depot26[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<3>;

	mov.u64 	%SPL, __local_depot26;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f1, [_D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_2];
	ld.param.u64 	%rd2, [_D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_1];
	ld.param.u64 	%rd1, [_D9bilateral6float4__T8opBinaryVAyaa1_2aZQtMFNaNbNiNffZSQCcQBv_param_0];
	st.f32 	[%SP+0], %f1;
	ld.f32 	%f2, [%rd2];
	ld.f32 	%f3, [%SP+0];
	mul.rn.f32 	%f4, %f2, %f3;
	st.f32 	[%rd1], %f4;
	ld.f32 	%f5, [%rd2+4];
	ld.f32 	%f6, [%SP+0];
	mul.rn.f32 	%f7, %f5, %f6;
	st.f32 	[%rd1+4], %f7;
	ld.f32 	%f8, [%rd2+8];
	ld.f32 	%f9, [%SP+0];
	mul.rn.f32 	%f10, %f8, %f9;
	st.f32 	[%rd1+8], %f10;
	ld.f32 	%f11, [%rd2+12];
	ld.f32 	%f12, [%SP+0];
	mul.rn.f32 	%f13, %f11, %f12;
	st.f32 	[%rd1+12], %f13;
	ret;

}
	// .weak	_D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv
.weak .func _D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv(
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_0,
	.param .b64 _D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_1,
	.param .b32 _D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_2
)
{
	.local .align 4 .b8 	__local_depot27[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<3>;

	mov.u64 	%SPL, __local_depot27;
	cvta.local.u64 	%SP, %SPL;
	ld.param.f32 	%f1, [_D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_2];
	ld.param.u64 	%rd2, [_D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_1];
	ld.param.u64 	%rd1, [_D9bilateral6float4__T8opBinaryVAyaa1_2fZQtMFNaNbNiNffZSQCcQBv_param_0];
	st.f32 	[%SP+0], %f1;
	ld.f32 	%f2, [%rd2];
	ld.f32 	%f3, [%SP+0];
	div.rn.f32 	%f4, %f2, %f3;
	st.f32 	[%rd1], %f4;
	ld.f32 	%f5, [%rd2+4];
	ld.f32 	%f6, [%SP+0];
	div.rn.f32 	%f7, %f5, %f6;
	st.f32 	[%rd1+4], %f7;
	ld.f32 	%f8, [%rd2+8];
	ld.f32 	%f9, [%SP+0];
	div.rn.f32 	%f10, %f8, %f9;
	st.f32 	[%rd1+8], %f10;
	ld.f32 	%f11, [%rd2+12];
	ld.f32 	%f12, [%SP+0];
	div.rn.f32 	%f13, %f11, %f12;
	st.f32 	[%rd1+12], %f13;
	ret;

}
